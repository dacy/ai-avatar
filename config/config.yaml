# AI Avatar Configuration

# Confluence connection settings
confluence:
  base_url: "https://your-confluence-instance.atlassian.net"
  username: "your-username"
  api_token: "your-api-token"
  space_key: "your-space-key"

# Embedding model settings
embedding:
  model_name: "all-MiniLM-L6-v2"  # HuggingFace model for generating embeddings
  dimension: 384  # Dimension of the embeddings
  chunk_size: 512  # Maximum size of text chunks for embedding
  overlap: 50  # Number of characters to overlap between chunks

# Vector search settings
search:
  index_path: "data/vectors/voice_search_index.faiss"  # Path to FAISS index file
  metadata_path: "data/vectors/voice_search_index.metadata"  # Path to metadata file
  max_results: 5  # Maximum number of results to return
  similarity_threshold: 0.0  # Minimum similarity score for results (0.0 means no threshold)
  index_type: "flat"  # FAISS index type: "flat", "ivf", or "hnsw"

# Speech processing settings
speech:
  whisper_model: "base"  # Whisper model size (tiny, base, small, medium, large)
  sample_rate: 16000  # Audio sample rate for speech recognition
  language: "en"  # Default language for speech recognition

# QA model settings
qa:
  mode: "generative"  # Options: "generative" or "extractive"
  
  # Generative QA settings (used when mode="generative")
  generative:
    model_name: "deepseek-r1:1.5b"  # Ollama model name
    api_url: "http://localhost:11434"  # Ollama API URL
    max_context_length: 4096  # Maximum context length for the model
    temperature: 0.7  # Temperature for text generation
    max_tokens: 512  # Maximum tokens to generate
    
  # Extractive QA settings (used when mode="extractive")
  extractive:
    model_name: "deepset/roberta-base-squad2"  # HuggingFace model name
    max_length: 100  # Maximum length of extracted answer
    confidence_threshold: 0.5  # Minimum confidence score for answers
    use_gpu: true  # Whether to use GPU for QA model

# Server settings
server:
  host: "0.0.0.0"  # Server host address
  port: 8000  # Server port
  debug: true  # Enable debug mode
  log_level: "info"  # Logging level (debug, info, warning, error)

# Data storage settings
storage:
  data_dir: "data"  # Root directory for all data
  raw_dir: "data/raw"  # Directory for raw data
  processed_dir: "data/processed"  # Directory for processed data
  vector_dir: "data/vectors"  # Directory for vector embeddings and indices 